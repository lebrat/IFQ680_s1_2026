{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44689c92-89df-4a88-8991-57009c91f7fe",
   "metadata": {},
   "source": [
    "# ML that can See: Supervised Learning with Images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84913b40-3370-40c7-8e00-b36d03f9f53d",
   "metadata": {},
   "source": [
    "Let's load in any libraries we will use in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b476050-46bf-4386-b90d-c3f49693a6df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#import torch which has many of the functions to build deep learning models and to train them\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#import torchvision, which was lots of functions for loading and working with image data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#this is a nice progress bar representation that will be good to measure progress during training\n",
    "import tqdm\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# fix seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# setup device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #this line checks if we have a GPU available\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743d496-b334-499f-b57f-da86a441f925",
   "metadata": {},
   "source": [
    "# 1. The Data\n",
    "\n",
    "We will use a subset of the **Stanford Dogs** dataset for **fine-grained image classification**. Our subset contains **20 dog breeds**, and the goal is to train a model to classify images into these classes. The dataset is already organized on disk into two main subfolders.\n",
    "\n",
    "The `train` and `test` folders contain subdirectories corresponding to the dog breeds (i.e. the class labels).  \n",
    "- The `train` folder will be used to create the **training** and **validation** sets (for hyperparameter tuning).\n",
    "- The `test` folder will be used as the **test set** to report final performance.\n",
    "\n",
    "### Task 1:\n",
    "\n",
    "1. Load the dataset using  \n",
    "   [`torchvision.datasets.ImageFolder`](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html), which loads images from a directory structure and **automatically assigns class labels** based on subfolder names.\n",
    "2. Load **one image from each class** and plot them as a **mosaic** using `matplotlib`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22beebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full training dataset first (without transforms for now)\n",
    "trainval_dataset = ...\n",
    "test_dataset = ...\n",
    "\n",
    "print(f'Trainval dataset size: {len(trainval_dataset)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')\n",
    "\n",
    "# Plot one random sample from each class in a horizontal stripe\n",
    "num_classes = 20\n",
    "fig, axes = plt.subplots(2, 10, figsize=(20, 6))\n",
    "\n",
    "# Get class names\n",
    "class_names = trainval_dataset.classes\n",
    "dataset_labels = np.array([label for _, label in trainval_dataset.samples])\n",
    "\n",
    "# For each class, find one sample and plot it\n",
    "for class_idx in range(num_classes):\n",
    "    class_indices = np.where(dataset_labels == class_idx)[0] \n",
    "    \n",
    "    # Pick a random sample from this class\n",
    "    sample_idx = np.random.choice(class_indices)\n",
    "    \n",
    "    # Load and display the image\n",
    "    img, _ = trainval_dataset[sample_idx]\n",
    "\n",
    "    row, col = int(class_idx // 10), int(class_idx % 10)\n",
    "    axes[row, col].imshow(img)\n",
    "    axes[row, col].set_title(class_names[class_idx].split('-')[-1], fontsize=10)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06584fdc",
   "metadata": {},
   "source": [
    "We should also examine the distribution of samples across the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_class_distribution(*datasets, dataset_names=None, figsize=(14, 6)):\n",
    "    \"\"\"\n",
    "    Plot the distribution of samples per class for multiple datasets.\n",
    "    \n",
    "    Args:\n",
    "        *datasets: Variable number of ImageFolder datasets or Subsets\n",
    "        dataset_names: List of names for each dataset (optional)\n",
    "        figsize: Figure size (width, height)\n",
    "    \"\"\"\n",
    "    \n",
    "    if dataset_names is None:\n",
    "        dataset_names = [f'dataset_{i}' for i in range(len(datasets))]\n",
    "    \n",
    "    # Collect data from all datasets\n",
    "    df_list = []\n",
    "    for dataset, name in zip(datasets, dataset_names):\n",
    "        # Handle both ImageFolder and Subset datasets\n",
    "        if hasattr(dataset, 'samples'):\n",
    "            # ImageFolder dataset\n",
    "            labels_full = [label for _, label in dataset.samples]\n",
    "            class_names = dataset.classes\n",
    "        else:\n",
    "            # Subset dataset - get labels from indices\n",
    "            labels_full = [dataset.dataset.targets[i] for i in dataset.indices]\n",
    "            class_names = dataset.dataset.classes\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'class': [class_names[label] for label in labels_full],\n",
    "            'split': name,\n",
    "            'count': 1\n",
    "        })\n",
    "        df_list.append(df)\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(df_list)\n",
    "    \n",
    "    # Group by class and split, then count\n",
    "    df_grouped = combined_df.groupby(['class', 'split']).count().reset_index()\n",
    "    \n",
    "    # Create grouped bar plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.barplot(data=df_grouped, x='class', y='count', hue='split')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Distribution of Samples per Class')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the distribution\n",
    "plot_class_distribution(trainval_dataset, test_dataset, dataset_names=['TrainVal', 'Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81fdc05",
   "metadata": {},
   "source": [
    "## Dataset Splitting\n",
    "Note that the classes contain **different numbers of samples**. This class imbalance should be taken into account when splitting the `trainval` dataset into **training** and **validation** sets. To preserve the class distribution in both splits, we use **stratification**.\n",
    "\n",
    "### Task 2:  \n",
    "Split the `trainval` dataset into **training (80%)** and **validation (20%)** sets using **stratified sampling**.\n",
    "\n",
    "**Hint:**  \n",
    "You can use the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    " function from `sklearn`, with the `stratify` argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a532ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Perform stratified split to maintain class distribution\n",
    "\n",
    "# Create subset datasets\n",
    "train_dataset = ...\n",
    "val_dataset = ...\n",
    "\n",
    "print(f\"Total trainval samples: {len(trainval_dataset)}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "plot_class_distribution(train_dataset, val_dataset, dataset_names=['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b81546",
   "metadata": {},
   "source": [
    "## Data Preprocessing, Augmentation, and Loading\n",
    "\n",
    "Since our dataset is relatively small and the images have **different sizes**, we need to perform a few preprocessing steps before feeding them to a deep learning model. PyTorch transforms module provides these functionalities:\n",
    "\n",
    "1. **Preprocessing:**  \n",
    "   - [`transforms.Resize`](https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html) – resize all images to a fixed size so they are compatible with the network (often 224 x 224 pixels).  \n",
    "   - [`transforms.ToTensor`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html) – convert images to PyTorch tensors and scale pixel values to the range [0, 1].  \n",
    "   - [`transforms.Normalize`](https://pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html) – normalize images using **ImageNet mean and standard deviation**, required when fine-tuning models pretrained on ImageNet.\n",
    "\n",
    "2. **Data Augmentation:**  \n",
    "   To artificially increase the effective dataset size and reduce overfitting, we can apply **random transformations** to training images, such as:  \n",
    "   - [`RandomResizedCrop`](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomResizedCrop.html) – randomly crops and resizes images.  \n",
    "   - [`RandomHorizontalFlip`](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomHorizontalFlip.html) – randomly flips images horizontally.  \n",
    "   - [`RandomVerticalFlip`](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomVerticalFlip.html) – randomly flips images vertically.  \n",
    "   - [`RandomRotation`](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomRotation.html) – randomly rotates images.  \n",
    "   - [`ColorJitter`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ColorJitter.html) – randomly adjusts brightness, contrast, saturation, and hue.\n",
    "\n",
    "   These transformations, applied sequentially and randomly, generate a wide variety of images from the same originals, helping the model generalize better.\n",
    "\n",
    "3. **Loading data in batches:**  \n",
    "   Deep learning models use **stochastic optimization**, processing images in batches rather than all at once. PyTorch’s [`DataLoader`](https://pytorch.org/vision/stable/data.html) class efficiently loads data in batches, shuffles the training set, and can use multiple worker threads for faster loading.\n",
    "\n",
    "### Task 3:\n",
    "\n",
    "1. **Preprocessing:**  \n",
    "   - Create a **transform pipeline** that resizes, converts to tensor, and normalizes images using ImageNet statistics.  \n",
    "   - Apply this transform to the validation and test datasets.\n",
    "\n",
    "\n",
    "3. **Data Augmentation:**  \n",
    "   - Create a **transform pipeline for training** that includes preprocessing and at least 2–3 random augmentations from the list above.  \n",
    "   - Apply this transform to the training dataset.\n",
    "\n",
    "\n",
    "4. **DataLoader:**  \n",
    "   - Create a **DataLoader** for each dataset (training, validation, and test).  \n",
    "   - Choose a suitable batch size.  \n",
    "   - Shuffle the training DataLoader; do not shuffle validation or test DataLoaders.  \n",
    "   - Optionally, use multiple workers to speed up loading.\n",
    "\n",
    "5.  **visualize a single batch from the training dataloader.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imnagenet preprocessing\n",
    "imagenet_means = (0.485, 0.456, 0.406)\n",
    "imagenet_stds = (0.229, 0.224, 0.225)\n",
    "\n",
    "# preprocessing transform\n",
    "transform = ...\n",
    "\n",
    "\n",
    "# Data augmentation transforms for training set\n",
    "train_transform = ...\n",
    "\n",
    "# Apply transforms to the datasets\n",
    "train_dataset.dataset.transform = transforms.Compose([train_transform,transform])\n",
    "val_dataset.dataset.transform = transform\n",
    "test_dataset.transform = transform\n",
    "\n",
    "# create dataloaders for train, val, test datasets\n",
    "batch_size = 16\n",
    "trainloader = ...\n",
    "valloader = ...\n",
    "testloader = ...\n",
    "\n",
    "# Visualize a batch of augmented training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Plot the batch\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 5))\n",
    "axes = axes.ravel()\n",
    "for idx in range(min(16, len(images))):\n",
    "    # Denormalize the image for visualization\n",
    "    img = images[idx].numpy().transpose((1, 2, 0))\n",
    "    # just remap for visualization\n",
    "    img = img * np.array(imagenet_stds) + np.array(imagenet_means)\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(class_names[labels[idx]])\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b7ba5-55b5-4350-abe2-9eb88cc38537",
   "metadata": {},
   "source": [
    "# 2. The Model\n",
    "\n",
    "This week we will use a pretrained ResNet18, that has been trained on ImageNet, but we will be freezing certain parameters in the model so that their weights do not update. We will do this to try and prevent the model from overfitting to the new, small dataset. You can also experiment other pretrained models provided by [PyTorch torchvision library](https://pytorch.org/vision/stable/models.html#classification).\n",
    "\n",
    "When we create a model for transfer learning, we should follow these steps:\n",
    "1. Initialise the model with pretrained weights.\n",
    "2. Adapt the architecture for the new number of classes in our new dataset by changing the final linear layer.\n",
    "3. If necessary, freeze any weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2943b5-399d-4e6b-970b-909859cd440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(model, num_classes, freeze_backbone = False):\n",
    "    \n",
    "    #### Adapt the architecture for the new number of classes.\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    #### If necessary, freeze any weights.\n",
    "    if freeze_backbone: \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze the parameters of the last fully connected layer\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "resnet_frozen = setup_model(backbone, 20, True)\n",
    "print(resnet_frozen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d207335-fe2e-4b0b-ac51-6e41528b136b",
   "metadata": {},
   "source": [
    "# 3. Training the Model with Transfer Learning\n",
    "\n",
    "Now that we know how to set up our model using **transfer learning**, we can start training it.\n",
    "\n",
    "We will use a **fine-tuning approach**, where the model’s parameters are slightly adjusted to adapt its learned features to the specific nuances of the new task. In this tutorial, we will **only update the parameters of the final linear layer**, keeping all other layers frozen. You can also experiment with training from scratch or finetune all layers.\n",
    "\n",
    "In the lecture, we reviewed the general training procedure:\n",
    "\n",
    "1. **Initialize the model.**\n",
    "2. **Define a loss function** (also called cost function or objective function).\n",
    "3. **Initialize the optimizer.**\n",
    "4. For `n` epochs (or until the loss converges/stops changing):\n",
    "    1. **Training phase:**  \n",
    "       - Put the model in training mode with `model.train()`.  \n",
    "       - For each batch in the **training dataset**:           \n",
    "           1. Perform a forward pass to compute predictions.\n",
    "           2. Calculate the **loss** and **accuracy**.\n",
    "           3. Perform a backward pass to compute gradients with respect to the parameters.\n",
    "           4. Update the parameters using the optimizer.\n",
    "    2. **Validation phase:**  \n",
    "       - Put the model in evaluation mode with `model.eval()`.  \n",
    "       - For each batch in the **validation dataset**:\n",
    "           1. Perform a forward pass to compute predictions.\n",
    "           2. Calculate the **loss** and **accuracy**.\n",
    "\n",
    "### Task 4\n",
    "In the cells below, implement the **training** and **validation** functions as described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c74c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, epoch, device):\n",
    "\n",
    "    # Put the model in \"train\" mode\n",
    "    model.train() \n",
    "\n",
    "    # For all batches in the training dataset\n",
    "    train_loss, correct, total = [], 0.0, 0.0\n",
    "    for _, data in  tqdm.tqdm(enumerate(dataloader, 0), total = len(dataloader), desc = f'Epoch {epoch+1} - training phase'):\n",
    "        # get the inputs and labels from the dataloader and move to device (GPU or CPU)\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "       # TODO\n",
    "\n",
    "    # average stats for the epoch\n",
    "    mean_train_loss = np.mean(train_loss)\n",
    "    train_accuracy = correct/total\n",
    "    print(f\"Training {epoch+1}: loss={mean_train_loss:.3f} acc={train_accuracy:.3f}\")\n",
    "\n",
    "    return mean_train_loss, train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, dataloader, criterion, epoch, device):\n",
    "\n",
    "    # Put the model in \"eval\" mode\n",
    "    model.eval()\n",
    "    \n",
    "    #Validation loop: For all batches in the validation dataset\n",
    "    with torch.no_grad(): # not build the computation graph for backpropagation, and thus, no gradients will be computed or stored for the tensors involved in those operations.\n",
    "        val_loss, val_correct, val_total = 0.0, 0.0, 0.0\n",
    "        for i, data in  tqdm.tqdm(enumerate(dataloader, 0), total = len(dataloader), desc = f'Epoch {epoch+1} - validation phase'):\n",
    "            # get the inputs and labels from the dataloader and move to device (GPU or CPU)\n",
    "            inputs, labels = data            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # TODO\n",
    "    \n",
    "    mean_val_loss = val_loss / val_total\n",
    "    val_accuracy = val_correct / val_total\n",
    "    print(f\"Validation {epoch+1}: loss={mean_val_loss:.3f} acc={val_accuracy:.3f}\")\n",
    "    return mean_val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07efb06a",
   "metadata": {},
   "source": [
    "Now let’s put everything together and train our model. Remember to save the best model, defined as the one that achieves the highest accuracy on the validation set at any epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any hyperparameters\n",
    "lr = 0.001\n",
    "total_epochs = 10\n",
    "\n",
    "#Initialise the model.\n",
    "backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "resnet_frozen = setup_model(backbone, 20, True)\n",
    "resnet_frozen = resnet_frozen.to(device)\n",
    "# Define a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialise the SGD optimizer.\n",
    "optimizer = optim.SGD(resnet_frozen.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "#Step 4: For n epochs (e.g. loss converged/stops changing)\n",
    "total_train_loss, total_val_loss = [], []\n",
    "total_train_acc, total_val_acc = [], []\n",
    "best_acc = -np.inf\n",
    "for epoch in range(total_epochs):    \n",
    "\n",
    "    # train for one epoch\n",
    "    mean_train_loss, train_accuracy = train_epoch(resnet_frozen, trainloader, criterion, optimizer, epoch, device)\n",
    "    total_train_loss.append(mean_train_loss); total_train_acc.append(train_accuracy);\n",
    "\n",
    "    # evaluate on validation set\n",
    "    mean_val_loss, val_accuracy = eval_epoch(resnet_frozen, valloader, criterion, epoch, device)\n",
    "    total_val_loss.append(mean_val_loss); total_val_acc.append(val_accuracy);\n",
    "\n",
    "    # save the best model based on validation accuracy\n",
    "    # TODO\n",
    "\n",
    "\n",
    "# Plot training and validation loss and accuracy curves\n",
    "plt.plot(total_train_loss, label = 'Train')\n",
    "plt.plot(total_val_loss, label = 'val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(total_train_acc, label = 'Train')\n",
    "plt.plot(total_val_acc, label = 'val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac0be29",
   "metadata": {},
   "source": [
    "# 4. Evaluation\n",
    "\n",
    "Once our model is trained, the next step is to **evaluate its performance** on the **test set**. Evaluation allows us to understand how well the model generalizes to **unseen data**.\n",
    "\n",
    "In this tutorial, we will focus on two basic metrics:\n",
    "\n",
    "1. **Accuracy** – the proportion of correctly predicted labels over all test samples.\n",
    "2. **Confusion Matrix** – a table that compares true class labels with predicted class labels, showing how many samples of each class are correctly classified and how many are misclassified into other classes. It helps identify which classes the model confuses more often.\n",
    "\n",
    "> Note: A more detailed discussion of evaluation metrics, such as precision, recall, F1-score, and ROC curves, will be covered in the next tutorial.\n",
    "\n",
    "For now, your task is to **run the model on the test set**, compute predictions for each sample, and report:\n",
    "\n",
    "- The **overall accuracy** of the model\n",
    "- The **confusion matrix** for the test set\n",
    "\n",
    "### Task 5\n",
    "\n",
    "1. Load the best model.\n",
    "2. Iterate over all batches in the **test DataLoader**.  \n",
    "3. For each sample, compute the **predicted label** using the trained model.  \n",
    "4. Collect the predictions and the ground-truth labels.  \n",
    "5. Compute and display:\n",
    "   - The **overall accuracy** (DONE)\n",
    "   - The **confusion matrix** (DONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Load the best model\n",
    "resnet_frozen.load_state_dict(torch.load(\"resnet_frozen_best.pth\"))\n",
    "resnet_frozen.eval()\n",
    "\n",
    "# Collect predictions and ground truth labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# compute predictions\n",
    "# TODO\n",
    "\n",
    "# Overall accuracy\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "test_accuracy = np.mean(all_predictions == all_labels)\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracies = []\n",
    "for class_idx in range(num_classes):\n",
    "    class_mask = all_labels == class_idx\n",
    "    class_accuracies.append((all_predictions[class_mask] == all_labels[class_mask]).sum() /float(class_mask.sum()))\n",
    "\n",
    "# Visualize per-class accuracy as a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(class_accuracies)), class_accuracies)\n",
    "plt.xticks(range(len(class_accuracies)), class_names, rotation=45, ha='right')\n",
    "plt.xlabel('Class'); plt.ylabel('Accuracy'); plt.title('Per-class Test Accuracy');\n",
    "plt.ylim([0, 1])\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label=f'Overall Accuracy: {test_accuracy:.4f}')\n",
    "plt.legend(); plt.tight_layout(); plt.show();\n",
    "\n",
    "# Compute and display confusion matrix using sklearn's ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay.from_predictions(all_labels, all_predictions, display_labels=class_names, \n",
    "                                               cmap=plt.cm.Blues, xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b2452",
   "metadata": {},
   "source": [
    "# 5. Extensions and Experiments\n",
    "\n",
    "Once you have completed training and evaluation with the current model, there are many ways you can **experiment and explore on your own** to deepen your understanding of CNNs and transfer learning:\n",
    "\n",
    "- **Change the backbone network:**  \n",
    "  Try replacing the current CNN with another architecture, such as **ResNet-50**, **EfficientNet**, or **MobileNet**, and observe how it affects accuracy and training speed.\n",
    "\n",
    "- **Use a foundation model:**  \n",
    "  You can explore **pretrained foundation models** such as **DINOv3** or other self-supervised models. Fine-tune them on this dataset and compare their performance to standard CNNs.\n",
    "\n",
    "- **Handle class imbalance:**  \n",
    "  If your dataset has classes with very different numbers of samples, try:\n",
    "  - Using **loss weights** in your loss function to give more importance to underrepresented classes.\n",
    "  - Using **sampling strategies** in the DataLoader (e.g., [`WeightedRandomSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler)) to balance the class distribution during training.  \n",
    "  These methods can help the model learn fairly across all classes.\n",
    "\n",
    "- **Experiment with data augmentation:**  \n",
    "  Try adding or modifying augmentations in your training pipeline (e.g., different crop sizes, rotations, color jitter, or even MixUp/CutMix). See how these changes impact generalization.\n",
    "\n",
    "- **Adjust training parameters:**  \n",
    "  Experiment with **learning rates**, **batch sizes**, **number of frozen layers**, or **optimizer types** to see how these hyperparameters affect convergence and final accuracy.\n",
    "\n",
    "- **Visualize model predictions:**  \n",
    "  Look at misclassified images in the test set or visualize feature maps from intermediate layers to gain insights into what the model has learned.\n",
    "\n",
    "> Tip: Keep a notebook or log of your experiments. Compare results systematically and try to identify patterns that improve performance. This will help you develop good practices for model development and fine-tuning in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f8071",
   "metadata": {},
   "source": [
    "# 6. Pro Tip: Hyperparameter Tuning with Optuna\n",
    "\n",
    "Hyperparameter selection can have a **big impact on model performance**. Instead of manually trying different values, you can use **Optuna**, a Python library for **automated hyperparameter optimization**.\n",
    "\n",
    "Optuna allows you to:\n",
    "\n",
    "- Define an **objective function** that trains and evaluates your model with a given set of hyperparameters.  \n",
    "- Specify **search spaces** for hyperparameters such as learning rate, batch size, optimizer type, or number of frozen layers.  \n",
    "- Automatically explore the hyperparameter space using **efficient sampling and pruning strategies** to find configurations that maximize performance.  \n",
    "\n",
    "**Example hyperparameters you could tune:**\n",
    "\n",
    "- Learning rate (`0.0001` to `0.01`)  \n",
    "- Batch size (`16`, `32`, `64`)  \n",
    "- Optimizer (`SGD` vs `Adam`)  \n",
    "- Weight decay  \n",
    "- Number of frozen layers in the backbone  \n",
    "\n",
    "### Challenge: \n",
    "\n",
    "As a challenge, you can use **Optuna** in combination with your **training and validation loop**.  \n",
    "\n",
    "> ⚠️ Note: This process can take a long time, and the study should be **saved to disk** so you can resume or analyze it later (see [Optuna documentation](https://optuna.readthedocs.io/en/stable/)).\n",
    "\n",
    "Here, we show a minimal example tuning **only the learning rate**, just for learning purposes.   You can extend this to **other hyperparameters** or more complex workflows.\n",
    "\n",
    "**Important:** Never use the **test set** during hyperparameter search. Doing so can **lead to overfitting** on the test set and your model may fail when deployed on unseen data.\n",
    "\n",
    "**Can you beat my model?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e77600f-3a44-4513-a951-9c43d839c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from optuna) (1.17.2)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from optuna) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from optuna) (2.0.44)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.12/site-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
      "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
      "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [optuna]2m1/2\u001b[0m [optuna]\n",
      "\u001b[1A\u001b[2KSuccessfully installed colorlog-6.10.1 optuna-4.6.0\n"
     ]
    }
   ],
   "source": [
    "# install optuna\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a0608-4a47-4f68-bdf6-176bc5eb0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# let's just use 4 epochs so it does not take alot of time\n",
    "total_epochs = 4\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    \n",
    "    ############## Suggest hyperparameters ############       \n",
    "    lr =  trial.suggest_float(\"lr\", 1e-3, 1e1, log=True)\n",
    "    # ... more can be included\n",
    "\n",
    "    ############## Training code as before ##########\n",
    "    #Initialise the model.\n",
    "    backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "    resnet_frozen = setup_model(backbone, 20, True)\n",
    "    resnet_frozen = resnet_frozen.to(device)\n",
    "    \n",
    "    # Define a loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialise the SGD optimizer.\n",
    "    optimizer = optim.SGD(resnet_frozen.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    #For n epochs (e.g. loss converged/stops changing)\n",
    "    total_train_loss, total_val_loss = [], []\n",
    "    total_train_acc, total_val_acc = [], []\n",
    "    best_acc = -np.inf\n",
    "    for epoch in range(total_epochs):    \n",
    "    \n",
    "        # train for one epoch\n",
    "        mean_train_loss, train_accuracy = train_epoch(resnet_frozen, trainloader, criterion, optimizer, epoch, device)\n",
    "        total_train_loss.append(mean_train_loss); total_train_acc.append(train_accuracy);\n",
    "    \n",
    "        # evaluate on validation set\n",
    "        mean_val_loss, val_accuracy = eval_epoch(resnet_frozen, valloader, criterion, epoch, device)\n",
    "        total_val_loss.append(mean_val_loss); total_val_acc.append(val_accuracy);\n",
    "    \n",
    "        # save validation accuracy to report to optuna\n",
    "        if val_accuracy > best_acc:            \n",
    "            best_acc = val_accuracy            \n",
    "\n",
    "    ############## give to optuna the best metric found (i.e. validation accuracy). Optuna will try to maximize this ############  \n",
    "    \n",
    "    return best_acc\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(study_name=\"hyperparameter Optimization\", direction=\"maximize\", storage=\"sqlite:///optuna_study.db\",)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best accuracy:\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
